# ğŸš€ Kubernetes Part 1 â€” Complete Revision Notes
> **Background assumed:** You know Docker & manual deployment on EC2/VMs

---

## ğŸ“Œ Table of Contents
1. [The Problem with Manual Deployment](#1-the-problem-with-manual-deployment)
2. [What is Kubernetes?](#2-what-is-kubernetes)
3. [Core Architecture](#3-core-architecture)
4. [Key Vocabulary](#4-key-vocabulary)
5. [Setting Up a Cluster](#5-setting-up-a-cluster)
6. [Pods](#6-pods)
7. [ReplicaSet](#7-replicaset)
8. [Deployment](#8-deployment)
9. [Why Deployment over ReplicaSet?](#9-why-deployment-over-replicaset)
10. [Services â€” Exposing Your App](#10-services--exposing-your-app)
11. [Full End-to-End Example](#11-full-end-to-end-example)
12. [Quick Command Reference](#12-quick-command-reference)

---

## 1. The Problem with Manual Deployment

You already know this from experience:

```
WITHOUT KUBERNETES (what you know):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  User Request
      â”‚
      â–¼
  Load Balancer (you set this up manually on AWS)
      â”‚
  â”Œâ”€â”€â”€â”´â”€â”€â”€â”
  â–¼       â–¼
EC2-1   EC2-2      â† you SSH into each, run docker run, manage crashes manually
(BE)    (BE)

EC2-3              â† separate machine for frontend
(FE)
```

**The problems you face:**
- App crashes at 3am â†’ you have to SSH and restart manually
- Traffic spikes â†’ you manually spin up more EC2s
- Deploying new version â†’ downtime or complex bash scripts
- Watching logs across 5 machines â†’ painful

**Kubernetes solves ALL of this.**

---

## 2. What is Kubernetes?

> **Simple definition:** Kubernetes is a system that manages your Docker containers automatically â€” starting them, healing them, scaling them, and exposing them.

```
WITH KUBERNETES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  User Request
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Kubernetes Cluster         â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Worker  â”‚  â”‚  Worker  â”‚    â”‚
â”‚  â”‚  Node 1  â”‚  â”‚  Node 2  â”‚    â”‚
â”‚  â”‚ [BE Pod] â”‚  â”‚ [BE Pod] â”‚    â”‚
â”‚  â”‚ [BE Pod] â”‚  â”‚ [FE Pod] â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Master  â”‚ â† YOU talk here  â”‚
â”‚  â”‚  Node    â”‚   via kubectl     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**You tell K8s:** "I want 3 nginx containers running always"  
**K8s handles:** where they run, restarting if they crash, updating them

---

## 3. Core Architecture

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              MASTER NODE (Control Plane)            â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚API Serverâ”‚  â”‚ etcd â”‚  â”‚ Scheduler â”‚  â”‚Ctrl  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚(gateway) â”‚  â”‚(DB)  â”‚  â”‚(placement)â”‚  â”‚Mgr   â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â–²                                                  â”‚
â”‚           â”‚ kubectl sends commands here                      â”‚
â”‚           â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   WORKER NODE 1  â”‚    â”‚   WORKER NODE 2  â”‚               â”‚
â”‚  â”‚                  â”‚    â”‚                  â”‚               â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚
â”‚  â”‚ â”‚   kubelet    â”‚ â”‚    â”‚ â”‚   kubelet    â”‚ â”‚               â”‚
â”‚  â”‚ â”‚(node agent)  â”‚ â”‚    â”‚ â”‚(node agent)  â”‚ â”‚               â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”    â”‚    â”‚ â”Œâ”€â”€â”€â”€â”           â”‚               â”‚
â”‚  â”‚ â”‚Pod â”‚ â”‚Pod â”‚    â”‚    â”‚ â”‚Pod â”‚           â”‚               â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜    â”‚    â”‚ â””â”€â”€â”€â”€â”˜           â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Master Node Components

| Component | What It Does | Analogy |
|-----------|-------------|---------|
| **API Server** | Entry point for all commands. Handles auth. | Reception desk |
| **etcd** | Key-value DB storing cluster state | The cluster's memory |
| **kube-scheduler** | Decides which worker node runs a new pod | HR assigning employees to offices |
| **kube-controller-manager** | Watches and maintains desired state | Manager who notices issues |

### Worker Node Components

| Component | What It Does | Analogy |
|-----------|-------------|---------|
| **kubelet** | Agent that runs on each node, manages pods | On-site supervisor |
| **kube-proxy** | Handles network routing to pods | Office receptionist/switchboard |
| **Container Runtime** | Actually runs containers (containerd/docker) | The actual worker |

---

## 4. Key Vocabulary

> Think of it as levels of abstraction, just like you have in Docker:

```
Docker World          Kubernetes World
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dockerfile        â†’   (same)
Docker Image      â†’   Image (pulled from DockerHub)
docker run nginx  â†’   Pod (running instance of image)
docker-compose    â†’   Deployment (manages multiple pods)
Multiple VMs      â†’   Cluster (group of nodes/machines)
```

### Full Hierarchy

```
CLUSTER
â””â”€â”€ NODES (machines)
    â”œâ”€â”€ Master Node (brain)
    â””â”€â”€ Worker Nodes (muscles)
        â””â”€â”€ PODS (smallest unit)
            â””â”€â”€ CONTAINERS (your actual app)
                â””â”€â”€ IMAGE (blueprint)
```

### Explained Simply

**Image** = your Docker image sitting on DockerHub. Blueprint. Not running.
```bash
# Example: the nginx image on DockerHub
https://hub.docker.com/_/nginx
```

**Container** = image that is running
```bash
docker run -p 3005:80 nginx
# â†‘ this creates a container from the nginx image
```

**Pod** = Kubernetes wrapper around one or more containers
```bash
# In K8s, instead of docker run, you do:
kubectl run nginx --image=nginx --port=80
# This creates a POD containing a container running nginx
```

**Node** = A machine (EC2 or local VM) in your cluster

**Cluster** = All your nodes together

---

## 5. Setting Up a Cluster

### Option A: Local with `kind` (Kubernetes IN Docker)

> Kind runs Kubernetes nodes as Docker containers on your laptop. 

```bash
# Install kind first: https://kind.sigs.k8s.io/docs/user/quick-start/#installation

# Single node cluster (not ideal)
kind create cluster --name local
docker ps   # you'll see 1 container: control-plane

# Delete it
kind delete cluster -n local
```

**Multi-node cluster (recommended):**

Create `clusters.yml`:
```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane    # the master/brain
  - role: worker           # worker 1
  - role: worker           # worker 2
```

```bash
kind create cluster --config clusters.yml --name local
docker ps
# You'll now see 3 containers: 1 control-plane + 2 workers
```

```
After running above:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ docker ps

CONTAINER ID   IMAGE                  COMMAND   NAMES
a1b2c3d4e5f6   kindest/node:v1.29.0   ...       local-control-plane
b2c3d4e5f6a1   kindest/node:v1.29.0   ...       local-worker
c3d4e5f6a1b2   kindest/node:v1.29.0   ...       local-worker2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Each Docker container = one K8s node
```

### Option B: Local with `minikube`

```bash
minikube start        # starts a single-node cluster
docker ps             # one container running (single-node)
```

> âš ï¸ Single node = control-plane also acts as worker. Not ideal for production but fine for learning.

### Install kubectl (the CLI tool)

```bash
# Install: https://kubernetes.io/docs/tasks/tools/#kubectl

kubectl get nodes     # list all nodes in your cluster
kubectl get pods      # list all running pods
```

---

## 6. Pods

### What is a Pod?

> A Pod is the **smallest deployable unit** in Kubernetes. It wraps one or more containers.

```
Analogy: 
  Docker  â†’ you run containers directly
  K8s     â†’ you never create containers directly
              you create PODS, and pods run containers

Pod
â””â”€â”€ Container 1 (nginx)     â† usually just one container per pod
â””â”€â”€ Container 2 (optional)  â† sometimes a "sidecar" container
```

### Creating a Pod

**Method 1: Command (quick & dirty)**
```bash
kubectl run nginx --image=nginx --port=80
```

**Method 2: Manifest YAML (correct way)**

Create `pod.yml`:
```yaml
apiVersion: v1          # K8s API version
kind: Pod               # type of resource
metadata:
  name: nginx           # name of this pod
spec:
  containers:
    - name: nginx       # name of container inside pod
      image: nginx      # Docker image to use
      ports:
        - containerPort: 80   # port the container listens on
```

```bash
kubectl apply -f pod.yml       # create/update
kubectl get pods               # check status
kubectl logs nginx             # see logs
kubectl describe pod nginx     # detailed info
kubectl delete pod nginx       # delete it
```

### What happens when you create a pod?

```
YOU
 â”‚
 â”‚  kubectl apply -f pod.yml
 â–¼
API Server (validates your request)
 â”‚
 â–¼
etcd (stores desired state: "I want 1 nginx pod")
 â”‚
 â–¼
Scheduler (picks a worker node for this pod)
 â”‚
 â–¼
kubelet on Worker Node (pulls nginx image, starts container)
 â”‚
 â–¼
ğŸŸ¢ Pod is Running
```

### Checking Pod Status

```bash
kubectl get pods
# NAME    READY   STATUS    RESTARTS   AGE
# nginx   1/1     Running   0          30s
#         â†‘ 1 container ready out of 1 total

kubectl get pods -owide
# Shows which NODE the pod is running on + its private IP
# NAME    READY   STATUS    IP           NODE
# nginx   1/1     Running   10.244.2.3   local-worker
```

> âš ï¸ The IP shown is a **private IP**. You can't access it from your browser directly. That's what Services are for (covered later).

---

## 7. ReplicaSet

### The Problem with Single Pods

```
Without ReplicaSet:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Pod crashes
      â”‚
      â–¼
  App is DOWN âŒ
  You get paged at 3am ğŸ˜­
  You SSH in, restart manually
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### What is a ReplicaSet?

> A ReplicaSet ensures that a **specified number of pod replicas are always running**. If one dies, it creates a new one automatically.

```
With ReplicaSet (replicas: 3):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Pod crashes
      â”‚
      â–¼
  ReplicaSet Controller notices: "I have 2 pods, I need 3"
      â”‚
      â–¼
  Creates new pod automatically âœ…
  You sleep peacefully ğŸ˜´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Creating a ReplicaSet

Create `rs.yml`:
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3                    # I want 3 pods always running
  selector:
    matchLabels:
      app: nginx                 # manage pods with this label
  template:                      # template for creating pods
    metadata:
      labels:
        app: nginx               # label applied to each pod
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

```bash
kubectl apply -f rs.yml
kubectl get rs
# NAME               DESIRED   CURRENT   READY   AGE
# nginx-replicaset   3         3         3       23s

kubectl get pods
# NAME                       READY   STATUS    RESTARTS   AGE
# nginx-replicaset-7zp2v     1/1     Running   0          35s
# nginx-replicaset-q264f     1/1     Running   0          35s
# nginx-replicaset-vj42z     1/1     Running   0          35s
#        â†‘ named as: replicaset-name + random-id
```

### Self-Healing Demo

```bash
# Delete one pod manually
kubectl delete pod nginx-replicaset-7zp2v

# Check immediately
kubectl get pods
# nginx-replicaset-q264f     1/1     Running   0    2m
# nginx-replicaset-vj42z     1/1     Running   0    2m
# nginx-replicaset-NEW123    1/1     Running   0    5s   â† NEW pod auto-created!
```

### Labels â€” How ReplicaSet Identifies "Its" Pods

```
ReplicaSet has: selector â†’ matchLabels â†’ app: nginx
                                               â†‘
Pods have:      labels   â†’ app: nginx   â†â”€â”€â”€â”€â”€â”€â”˜
                
If labels match â†’ ReplicaSet manages that pod
```

**Interesting experiment:**
```bash
# Try adding a pod with app=nginx label manually
kubectl run extra-pod --image=nginx --labels="app=nginx"

# RS already has 3 pods â†’ it will IMMEDIATELY TERMINATE your extra pod!
kubectl get pods   # you'll see extra-pod briefly then it's gone
```

---

## 8. Deployment

### What is a Deployment?

> A Deployment is a **higher-level abstraction that manages ReplicaSets**. When you update your app, Deployment handles the transition safely.

```
Hierarchy:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  YOU
   â”‚  apply deployment.yml
   â–¼
  DEPLOYMENT         â† manages updates, rollbacks
   â”‚  creates
   â–¼
  REPLICASET         â† manages number of pods
   â”‚  creates
   â–¼
  PODS               â† actual running containers
   â”‚  runs
   â–¼
  CONTAINERS         â† your app
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Creating a Deployment

Create `deployment.yml`:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

```bash
kubectl apply -f deployment.yml

kubectl get deployment
# NAME               READY   UP-TO-DATE   AVAILABLE   AGE
# nginx-deployment   3/3     3            3           18s

kubectl get rs
# NAME                          DESIRED   CURRENT   READY   AGE
# nginx-deployment-576c6b7b6    3         3         3       34s
#        â†‘ deployment-name + hash (hash represents current config)

kubectl get pods
# NAME                                READY   STATUS    RESTARTS   AGE
# nginx-deployment-576c6b7b6-b6kgk    1/1     Running   0          46s
# nginx-deployment-576c6b7b6-m8ttl    1/1     Running   0          46s
# nginx-deployment-576c6b7b6-n9cx4    1/1     Running   0          46s
#        â†‘ deployment-rs-hash + pod-random-id
```

### Passing Environment Variables

```yaml
spec:
  containers:
    - name: postgres
      image: postgres:latest
      ports:
        - containerPort: 5432
      env:
        - name: POSTGRES_PASSWORD    # env variable name
          value: "mysecretpassword"  # env variable value
```

This is equivalent to:
```bash
# Docker world:
docker run -e POSTGRES_PASSWORD=mysecretpassword postgres

# K8s world: put it in the YAML above
```

---

## 9. Why Deployment over ReplicaSet?

### The Key Reason: Safe Rollouts

**Experiment â€” bad image deployment:**

Update your `deployment.yml` to use a fake image:
```yaml
image: nginx2:latest   # this image doesn't exist!
```

```bash
kubectl apply -f deployment.yml
kubectl get rs
```

```
WHAT YOU'LL SEE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-576c6b7b6    3         3         3       14m   â† OLD (still running! âœ…)
nginx-deployment-5fbd4799cb   1         1         0       2m    â† NEW (failing âŒ)

kubectl get pods:
nginx-deployment-576c6b7b6-9nlnq    1/1   Running          0    15m  âœ…
nginx-deployment-576c6b7b6-m8ttl    1/1   Running          0    15m  âœ…
nginx-deployment-576c6b7b6-n9cx4    1/1   Running          0    15m  âœ…
nginx-deployment-5fbd4799cb-fmt4f   0/1   ImagePullBackOff 0    2m   âŒ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Your app is STILL RUNNING because Deployment kept the old RS alive!
With just a ReplicaSet, you'd have killed all 3 pods first. App = DOWN.
```

```
Rolling Update Strategy (Deployment handles this):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  OLD VERSION: Pod1âœ…  Pod2âœ…  Pod3âœ…

  Step 1: Start new Pod â†’ Pod1âœ…  Pod2âœ…  Pod3âœ…  NewPodğŸ”„
  Step 2: New pod healthy? â†’ Kill Old Pod1
          Result:           Pod2âœ…  Pod3âœ…  NewPodâœ…
  Step 3: Repeat until all pods updated
  
  If new pod FAILS: stop rollout, keep old pods running
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Rollback

```bash
# Check rollout history
kubectl rollout history deployment/nginx-deployment
# REVISION  CHANGE-CAUSE
# 1         <none>     â† original nginx:latest
# 2         <none>     â† bad nginx2:latest

# Undo last deployment (go back to revision 1)
kubectl rollout undo deployment/nginx-deployment

# Your old 3 pods come back âœ…
kubectl get pods
```

---

## 10. Services â€” Exposing Your App

### The Problem

```
After creating a deployment:

kubectl get pods -owide
NAME                                READY   STATUS    IP            NODE
nginx-deployment-576c6b7b6-7jrn5    1/1     Running   10.244.2.3    worker1
nginx-deployment-576c6b7b6-88fkh    1/1     Running   10.244.1.4    worker2
nginx-deployment-576c6b7b6-zf8ff    1/1     Running   10.244.2.5    worker1

The IPs (10.244.x.x) are PRIVATE â†’ you can't hit them from your browser
```

### What is a Service?

> A Service is a **stable endpoint** that exposes your pods to the world. Pods can die and be recreated with new IPs â€” the Service IP stays the same.

```
Without Service:           With Service:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Your Browser               Your Browser
       â”‚                           â”‚
       â”‚ ??? which IP ???          â”‚ hits Service (stable IP)
       â–¼                           â–¼
  Pod (10.244.2.3)          Service (fixed address)
                                   â”‚
                              â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                              â–¼         â–¼
                         Pod 1      Pod 2      â† load balanced!
```

### 3 Types of Services

```
1. ClusterIP (default)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Only accessible INSIDE the cluster
   Use case: Pod-to-pod communication
   (e.g., your backend talking to postgres)

   Internet  âœ—â†’  [Service: ClusterIP]  â†’  Pods
   
2. NodePort
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Accessible from OUTSIDE via NodeIP:NodePort
   Port range: 30000-32767
   Use case: Development/testing

   Internet  â†’  Node:30007  â†’  [Service: NodePort]  â†’  Pods

3. LoadBalancer
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Cloud provider creates a public load balancer
   Use case: Production on cloud (AWS, GCP, Vultr)

   Internet  â†’  [Cloud LB: 52.x.x.x]  â†’  [Service: LoadBalancer]  â†’  Pods
```

### NodePort Service (Local Development)

**Step 1:** Create `kind.yml` with port forwarding:
```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
    extraPortMappings:
      - containerPort: 30007   # port inside cluster
        hostPort: 30007        # port on your laptop
  - role: worker
  - role: worker
```

```bash
kind create cluster --config kind.yml --name local
```

**Step 2:** Create `deployment.yml` (nginx with 3 replicas â€” same as before)

**Step 3:** Create `service.yml`:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx          # targets pods with this label
  ports:
    - protocol: TCP
      port: 80          # service port (inside cluster)
      targetPort: 80    # pod's port
      nodePort: 30007   # external port (30000-32767)
  type: NodePort
```

```bash
kubectl apply -f deployment.yml
kubectl apply -f service.yml

# Now visit: http://localhost:30007 â†’ you'll see nginx! ğŸ‰
```

```
What happens when you hit localhost:30007:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Your Browser
      â”‚  http://localhost:30007
      â–¼
  Kind's port mapping (hostPort:30007 â†’ containerPort:30007)
      â”‚
      â–¼
  Kubernetes Node
      â”‚
      â–¼
  NodePort Service (port 30007)
      â”‚  picks one of the pods (round-robin)
  â”Œâ”€â”€â”€â”´â”€â”€â”€â”
  â–¼       â–¼
Pod 1   Pod 2   Pod 3
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### LoadBalancer Service (Production on Cloud)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer    # no nodePort needed â€” cloud handles it
```

```bash
kubectl apply -f service-lb.yml
kubectl get service
# NAME            TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)
# nginx-service   LoadBalancer   10.96.1.100   52.14.xxx.xxx   80:31456/TCP
#                                              â†‘ public IP assigned by cloud!
```

---

## 11. Full End-to-End Example

Here's everything together â€” deploy nginx and expose it:

### File Structure
```
k8s-demo/
â”œâ”€â”€ kind.yml           # cluster config
â”œâ”€â”€ deployment.yml     # your app pods
â””â”€â”€ service.yml        # expose the app
```

### `kind.yml`
```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
    extraPortMappings:
      - containerPort: 30007
        hostPort: 30007
  - role: worker
  - role: worker
```

### `deployment.yml`
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

### `service.yml`
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30007
  type: NodePort
```

### Commands in Order
```bash
# 1. Create cluster
kind create cluster --config kind.yml --name local

# 2. Verify cluster
kubectl get nodes

# 3. Deploy app
kubectl apply -f deployment.yml

# 4. Check pods
kubectl get pods

# 5. Expose app
kubectl apply -f service.yml

# 6. Visit http://localhost:30007 in browser ğŸ‰

# --- If you update the image ---
# 7. Edit deployment.yml (change image version)
kubectl apply -f deployment.yml

# 8. Watch rolling update
kubectl rollout status deployment/nginx-deployment

# --- If something breaks ---
# 9. Roll back
kubectl rollout undo deployment/nginx-deployment

# --- Cleanup ---
kubectl delete deployment nginx-deployment
kubectl delete service nginx-service
kind delete cluster -n local
```

---

## 12. Quick Command Reference

### Cluster
```bash
kind create cluster --name local                          # single node
kind create cluster --config clusters.yml --name local   # multi node
kind delete cluster -n local                             # delete cluster
kubectl get nodes                                        # list nodes
```

### Pods
```bash
kubectl run nginx --image=nginx --port=80   # create pod (imperative)
kubectl apply -f pod.yml                    # create pod (declarative)
kubectl get pods                            # list pods
kubectl get pods -owide                     # list pods with IPs and nodes
kubectl logs nginx                          # see logs
kubectl logs -f nginx                       # follow logs (live)
kubectl describe pod nginx                  # detailed info
kubectl delete pod nginx                    # delete pod
```

### ReplicaSet
```bash
kubectl apply -f rs.yml          # create replicaset
kubectl get rs                   # list replicasets
kubectl delete rs nginx-rs       # delete rs (also deletes pods)
```

### Deployment
```bash
kubectl apply -f deployment.yml                       # create/update deployment
kubectl get deployment                                # list deployments
kubectl rollout status deployment/nginx-deployment    # watch rollout progress
kubectl rollout history deployment/nginx-deployment   # see revision history
kubectl rollout undo deployment/nginx-deployment      # rollback
kubectl delete deployment nginx-deployment            # delete deployment
```

### Service
```bash
kubectl apply -f service.yml     # create service
kubectl get service              # list services (shows EXTERNAL-IP for LB)
kubectl delete service nginx-svc # delete service
```

### Debugging
```bash
kubectl describe pod <pod-name>     # events, errors, config
kubectl logs <pod-name>             # stdout logs
kubectl logs -f <pod-name>          # live logs
kubectl get events                  # cluster-wide events
kubectl get nodes --v=8             # see raw HTTP requests to API
```

---

## ğŸ§  Mental Model Summary

```
WHAT YOU WRITE        WHAT K8S CREATES           WHAT RUNS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deployment.yml   â†’    Deployment                 
                       â””â”€â”€ ReplicaSet            
                            â”œâ”€â”€ Pod 1      â†’     Container (nginx)
                            â”œâ”€â”€ Pod 2      â†’     Container (nginx)
                            â””â”€â”€ Pod 3      â†’     Container (nginx)

service.yml      â†’    Service (NodePort/LB)
                       â””â”€â”€ Routes traffic to Pods via labels
```

```
KEY RULES TO REMEMBER:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Always use Deployments (not raw Pods or ReplicaSets directly)
âœ… Labels are how K8s connects things (Service â†’ Pods, RS â†’ Pods)
âœ… Pods have private IPs â€” always use Services to expose them
âœ… Deployment = rolling updates + rollback for free
âœ… kubectl apply -f is idempotent â€” safe to run multiple times
âœ… etcd = source of truth. K8s always tries to match actual state to desired state
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

*Notes based on 100xDevs Kubernetes Part 1 â€” Page 2 of 20*
